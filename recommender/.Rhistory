employee_info["salary_change" > 0, ]
employee_info["salary_change" > 0, ]
employee_info[employee_info$salary_change > 0, ]
# How many employees got a raise?
employee_with_raise <- employee_info[employee_info$salary_change > 0, ]
dim(employee_with_raise)
nrow <- dim(employee_with_raise)[1]
nrow <- dim(employee_with_raise)[2]
nrow <- dim(employee_with_raise)[1]
# What was the dollar value of the highest raise?
employee_info[max(employee_info$change),  ]
# What was the 2018 salary of employee 57
employee_info[57, salaries]
# What was the 2018 salary of employee 57
employee_info[57, colnames((salaries))]
# What was the 2018 salary of employee 57
employee_info[57, 2]
# What was the dollar value of the highest raise?
employee_info[max(change),  ]
# What was the dollar value of the highest raise?
employee_info[max(4),  ]
# What was the dollar value of the highest raise?
employee_info[4,  ]
# Your script for Part 1 goes here (and delete this comment!)
names <- c("Michelle Ho", "Patricia Au", "Anukriti Goyal", "Andrew Kan", "Bao Dinh", "Kishore Vasan" )
math_grades <- runif(6, 0, 100)
math_grades <- round(runif(6, 0, 100))
math_grades <- round(runif(6, 80, 100))
spanish_grades <- round(runit(6, 80, 100))
spanish_grades <- round(runif(6, 80, 100))
tas <- data.frame(names, math_grades, spanish_grades stringsAsFactors = FALSE)
tas <- data.frame(names, math_grades)
tas <- data.frame(names, math_grades, spanish_grades)
view(tas)
View(tas)
View(tas)
dimensions_of_tas - dim.data.frame(tas)
dimensions_of_tas <- dim.data.frame(tas)
print(paste("The TA data fram has", dimensions_of_tas[1], "rows and", dimensions_of_tas[2], "cols:",
tas[1, ],))
print(paste("The TA data fram has", dimensions_of_tas[1] ))
print(paste("The TA data fram has", dimensions_of_tas[1], "rows and", dimensions_of_tas[2], "cols:",
tas[1, ]))
print(paste("The TA data fram has", dimensions_of_tas[1], "rows and", dimensions_of_tas[2], "cols:",
colnames(tas)))
colnames(c(tas)))
print(colnames(tas))
col_names <- paste(colnames(tas))
print(paste("The TA data fram has", dimensions_of_tas[1], "rows and", dimensions_of_tas[2], "cols:",
col_names))
col_names <- paste(colnames(tas), collapse = TRUE)
col_names <- paste(colnames(tas), collapse = NULL)
print(paste("The TA data fram has", dimensions_of_tas[1], "rows and", dimensions_of_tas[2], "cols:",
col_names))
print(colnames(tas))
col_names <- paste(colnames(tas), collapse = " ")
print(paste("The TA data fram has", dimensions_of_tas[1], "rows and", dimensions_of_tas[2], "cols:",
col_names))
col_names <- paste(colnames(tas), collapse = ",")
print(paste("The TA data fram has", dimensions_of_tas[1], "rows and", dimensions_of_tas[2], "cols:",
col_names))
col_names <- paste(colnames(tas), collapse = ", ")
print(paste("The TA data fram has", dimensions_of_tas[1], "rows and", dimensions_of_tas[2], "cols:",
col_names))
print(paste("The TA data fram has", dimensions_of_tas[1], "rows and", dimensions_of_tas[2], "cols:",
col_names))
row.names(tas) <- names
print(tas["Bao Dinh", ])
grad_diff <- tas[, math_grades] - tas[, spanish_grades]
grad_diff <- math_grades - spanish_grades
tas$grad_diff <- grad_diff
grad_diff[grad_diff > 0]
# Your script for Part 1 goes here (and delete this comment!)
names <- c("Michelle Ho", "Patricia Au", "Anukriti Goyal", "Andrew Kan", "Bao Dinh", "Kishore Vasan" )
better_at_math <- grad_diff > 0
tas$better_at_math <- better_at_math
tas_better_at_math <- tas[tas$better_at_math > 0]
row.names(tas) <- names
print(tas["Bao Dinh", ])
grad_diff <- math_grades - spanish_grades
tas$grad_diff <- grad_diff
better_at_math <- grad_diff > 0
tas$better_at_math <- better_at_math
tas_better_at_math <- tas[tas$better_at_math > 0]
tas_better_at_math <- tas[tas$better_at_math > 0, ]
num_better_at_math <- dim.data.frame(tas_better_at_math)
num_better_at_math <- dim.data.frame(tas_better_at_math)[1]
print(num_better_at_math)
#################
#### PART 1 #####
#################
# A vector of names of all tas of info 201
names <- c("Michelle Ho", "Patricia Au", "Anukriti Goyal", "Andrew Kan", "Bao Dinh",
"Kishore Vasan" )
# A vector of numbers that are the math grades of the tas
math_grades <- round(runif(6, 80, 100))
# A vector of numbers that are the spanish grades of the tas
spanish_grades <- round(runif(6, 80, 100))
# A data fram of the names, math grades, and spanish grades of the tas
tas <- data.frame(names, math_grades, spanish_grades, stringsAsFactors = FALSE)
# A varible gives the dimensions of the data frame tas
dimensions_of_tas <- dim.data.frame(tas)
# a Varible that turns the column titles into a string and then prints a sentence describing the
# data frames's dimensions.
col_names <- paste(colnames(tas), collapse = ", ")
print(paste("The TA data fram has", dimensions_of_tas[1], "rows and", dimensions_of_tas[2],
"cols:", col_names))
#sets the row names of the data fram to the names of the tas
row.names(tas) <- names
#prints out the row of my TA
print(tas["Bao Dinh",])
# A variable that finds the difference between the math and spanish grades. Then adds a column
# with the differences
grad_diff <- math_grades - spanish_grades
tas$grad_diff <- grad_diff
# A varible that determines if the TA has a higher math grade compared to spanish. Creates a
# column weather the TA is better at Math
better_at_math <- grad_diff > 0
tas$better_at_math <- better_at_math
# The following code counts how many tas are better at math
tas_better_at_math <- tas[tas$better_at_math > 0, ]
num_better_at_math <- nrow(tas_better_at_math)
print(num_better_at_math)
# creates a CSV file of the tas data frame.
write.csv(tas, 'tas.csv', row.names = FALSE)
#################
#### PART 2 #####
#################
# A varible that takes in the csv file "life_expectancy"
life_expectancy <- read.csv('data/life_expectancy.csv', stringsAsFactors = FALSE)
# the following varible finds the difference between le_2013 and le_1960, then adds a column with
# the differences
life_expectancy_diff <- life_expectancy$le_2013 - life_expectancy$le_1960
life_expectancy$change <- life_expectancy_diff
# the following lines of code finds and prints the countries with a life expectancy increase of
# less then 5 years
num_small_gain <- life_expectancy[life_expectancy_diff < 5, ]
print(num_small_gain[,"country" ])
# This varible finds the country with the highest change in life expectancy
most_improve <- life_expectancy[max(life_expectancy$change), ]
# This Function takes a country's name and returns the change in life expectancy of that
# country
country_change <- function(country_name){
rownames(life_expectancy) <- life_expectancy$country
life_expectancy[country_name, "change"]
}
# prints out the life expectancy change of Haiti
print(country_change("Haiti"))
# This Function takes the name of a region and return the country with the lowest life expectancy
# of 2013
lowest_life_exp_in_region <- function(region_name){
region_data <- life_expectancy[life_expectancy$region == region_name, ]
lowest_of_current <- region_data[region_data$le_2013 == min(region_data$le_2013), "country"]
}
# prints out the lowest life expectancy country of the latin america & Caribbean region
print(lowest_life_exp_in_region("Latin America & Caribbean"))
# This function takes in two countries and comparies their life expectancyies in 2013 and their
# change
compare_countries <- function(country1, country2){
country_filter <- life_expectancy$country == country1 | life_expectancy$country == country2
life_expectancy[country_filter, c('country', 'le_2013', 'change')]
}
# The varible comparies the US and Cuba
us_vs_cuba <- compare_countries("United States", "Cuba")
#################
#### PART 3 #####
#################
# loads the data Titanic
data("Titanic")
# determines if the data Titanic is a data frame
is.data.frame(Titanic)
# This varible makes the Titanic data a data frame
Titanic_data_frame <- as.data.frame(Titanic, stringsAsFactors = FALSE)
# A varible that finds all the rows that involve children in the Titanic_data_frame
children <- Titanic_data_frame[Titanic_data_frame$Age == "Child",]
# A varible that finds the total amount of children
children_num <- sum(children$Freq)
# the following lines of code finds and prints the row of that has the largest amount of non
# survivors
did_not_survive_data <- Titanic_data_frame[Titanic_data_frame$Survived == "No", ]
largest_lost_row <- did_not_survive_data[did_not_survive_data$Freq == max(did_not_survive_data$Freq), ]
print(largest_lost_row)
# That the class Crew had the lowest priority when it came to the evacuation.
# This function takes in a class type and returns sentence telling the percentage of men and women
#  and children that survived out of the total men, and total women and children.
survival_rate <- function(class){
# filters the Titanic data frame to only show the typed class
class_data <- Titanic_data_frame[Titanic_data_frame$Class == class, ]
# The varible finds all Adult males in the class_data then sums how many of them there are
male_age_data <- class_data[class_data$Age == 'Adult' & class_data$Sex == 'Male', ]
all_males <- sum(male_age_data$Freq)
# This varible filters out the males who died then sums up how many surviors then finds the
# precentage that survives
male_survived_data <- male_age_data[male_age_data$Survived == "Yes", ]
all_survive_males <- sum(male_survived_data$Freq)
male_survival_ratio <- round((all_survive_males / all_males) * 100)
# Finds all the non males in the Titanic data frame then finds the total
nonmale_data <- class_data[class_data$Sex != "Male", ]
all_women_children <- sum(nonmale_data$Freq)
# Filters out the ones who died then totals the surviors then finds the survior ratio
women_children_survive_data <- nonmale_data[nonmale_data$Survived == "Yes", ]
all_survived_women_children <- sum(women_children_survive_data$Freq)
nonmale_survival_ratio <- round((all_survived_women_children / all_women_children) * 100)
# creates a sentence that states the precentage of men and women and children that survived in
# there class.
summary <- paste("Of ", class, " class, ", male_survival_ratio, "% of men survived and ",
nonmale_survival_ratio, "% of women and children survived", sep = "")
}
# prints the survival rate of 1st, 2nd, and 3rd class
print(c(survival_rate("1st"), survival_rate("2nd"), survival_rate("3rd")))
# the women and children first policy save almost all women and children from the 1st and 2n
# classes but it seem to not have save as many in the 3rd class. This is probably due to when
# the crew did begin evacuating the 3rd class passengers the ship was close to going under and
# there weren't enough life boats too.
tas$grad_diff <- math_grades - spanish_grades
View(tas)
# the following lines of code finds and prints the row of that has the largest amount of non
# survivors
did_not_survive_data <- Titanic_data_frame[Titanic_data_frame$Survived == "No", ]
largest_lost_row <- did_not_survive_data[did_not_survive_data$Freq ==
max(did_not_survive_data$Freq), ]
print(largest_lost_row)
install.packages(shiny)
install.packages("shiny")
library("shiny")
library("shiny")
header <- h1("Hello, My name is elder ")
my_ui <- fluidPage(
header,
p("what is your name")
)
install.package("shiny")
shinyApp(ui = my_ui, server = my_server)
library("shiny")
header <- h1("Hello, My name is elder ")
my_ui <- fluidPage(
header,
p("what is your name")
)
my_server <- function(input, output) {
}
shinyApp(ui = my_ui, server = my_server)
install.packages('rsconnect')
rsconnect::setAccountInfo(name='dpham',
token='A746228B0A4AC7BDE12578E01781C198',
secret='mQDmDZJn5UyLsb/4eAr2SqUhOaaUHh3Vr/uR2ZiL')
rsconnect::setAccountInfo(name='dpham',
token='A746228B0A4AC7BDE12578E01781C198',
secret='mQDmDZJn5UyLsb/4eAr2SqUhOaaUHh3Vr/uR2ZiL')
library("shiny")
header <- h1("Hello")
my_ui <- fluidPage(
header,
p("what is your name")
)
my_server <- function(input, output) {
}
shinyApp(ui = my_ui, server = my_server)
shinyApp(ui = my_ui, server = my_server)
shiny::runApp('UW class docs/Senior Year/Info 201/a8-data-app-pham4396')
?textInput
?tabPanel
runApp('UW class docs/Senior Year/Info 201/a8-data-app-pham4396')
shiny::runApp('UW class docs/Senior Year/Info 201/a8-data-app-pham4396')
# Load in 'rvest' package
library('rvest')
## Uncomment this to install packages
install.packages('rvest')
# Load in 'rvest' package
library('rvest')
'Specify the URL endpoint we are using'
url <- 'http://www.imdb.com/search/title?count=100&release_date=2016,2016&title_type=feature'
webpage <- read_html(url)
rank_data_html <- html_nodes(webpage,'.text-primary')
rank_data <- html_text(rank_data_html)
head(rank_data)
rank_data<-as.numeric(rank_data)
head(rank_data)
#Using CSS selectors to scrape the title section
title_data_html <- html_nodes(webpage, '.lister-item-header a')
#html to text
title_data <- html_text(title_data_html)
#look at data
head(title_data)
#Using CSS selectors to scrape the description section
description_data_html <- html_nodes(webpage, '.ratings-bar+ .text-muted')
#Converting the description data to text
description_data <_ html_text(description_data_html)
#Converting the description data to text
description_data <- html_text(description_data_html)
#look at data
head(description_data)
install.packages('syuzhet')
library(dplyr)
library(stringr)
library(tidytext)
library(tidyr)
library(ggplot2)
# install.packages('dplyr')
# install.packages('stringr')
install.packages('tidytext')
#install.packages('syuzhet')
library(syuzhet)
# Create a vector of emotional sentences.
# Add some happy ones, angry ones - you name it!
student_sentences <- c('I really like the pie you gave me this morning.',
'Your shoes suck and are just plain ugly.',
'I\'d really truly love going out in this weather!'
)
# Analyze sentiment for student sentences
student_sentiments <- data.frame(get_sentiment(student_sentences, method = 'syuzhet'))
# Create a vector of emotional sentences.
# Add some happy ones, angry ones - you name it!
student_sentences <- c('I really like the pie you gave me this morning.',
'Your shoes suck and are just plain ugly.',
'I\'d really truly love going out in this weather!'
)
# Analyze sentiment for student sentences
student_sentiments <- data.frame(get_sentiment(student_sentences, method = 'syuzhet'))
View(student_sentiments)
# Create a vector of emotional sentences.
# Add some happy ones, angry ones - you name it!
student_sentences <- c('I really like the pie you gave me this morning.',
'Your shoes suck and are just plain ugly.',
'I\'d really truly love going out in this weather!',
'I Love Info',
'The weather makes me feel hungry')
# Analyze sentiment for student sentences
student_sentiments <- data.frame(get_sentiment(student_sentences, method = 'syuzhet'))
library(dplyr)
library(stringr)
library(tidytext)
library(tidyr)
library(ggplot2)
##### LEXICONS #####
# Use the get_sentiments() function to get your dictionary of positive
# and negative words. Use the lexicon which categorizes words into
# positive and negative.
View(get_sentiments("nrc"))
##### LEXICONS #####
# Use the get_sentiments() function to get your dictionary of positive
# and negative words. Use the lexicon which categorizes words into
# positive and negative.
View(get_sentiments("aphin"))
##### LEXICONS #####
# Use the get_sentiments() function to get your dictionary of positive
# and negative words. Use the lexicon which categorizes words into
# positive and negative.
View(get_sentiments("bing"))
##### LEXICONS #####
# Use the get_sentiments() function to get your dictionary of positive
# and negative words. Use the lexicon which categorizes words into
# positive and negative.
bing_sentiments <- (get_sentiments("bing"))
##### DATA ANALYSIS + WRANGLING #####
# Read books data in
books <- read.csv('./data/austen_books.csv', stringsAsFactors = FALSE)
setwd("~/UW class docs/Senior Year/Info 201/mini-demos/sentiment_analysis")
##### DATA ANALYSIS + WRANGLING #####
# Read books data in
books <- read.csv('./data/austen_books.csv', stringsAsFactors = FALSE)
jane_austen_sentiment <- books %>%
inner_join(bing_sentiments, by = "words")
jane_austen_sentiment <- books %>%
inner_join(bing_sentiments, by = "word")
View(jane_austen_sentiment)
# Instead of having each individual word, count the number of positive/negative
# words in each chapter.
jane_austen_sentiment <- jane_austen_sentiment %>%
count(book, chapter, sentiment)
View(jane_austen_sentiment)
jane_austen_sentiment <- jane_austen_sentiment %>%
spread(sentiment, n, fill = 0)
View(jane_austen_sentiment)
jane_austen_sentiment <- jane_austen_sentiment %>%
spread(sentiment, n, fill = 0)
jane_austen_sentiment <- jane_austen_sentiment %>%
spread(sentiment, n, fill = 0) %>%
mutate(sentiment= positive - negative)
setwd("~/UW class docs/Senior Year/Info 201/mini-demos/knn-exercise")
#load library
library(class) #Has the knn function
#loading data
data("iris")
#Set the seed for reproducibility
set.seed(4948493)
#Sample the Iris data set (70% train, 30% test)
ir_sample <- sample(1:nrow(iris),size=nrow(iris)*.7)
ir_train <- iris[ir_sample,] #Select the 70% of rows
ir_test <- iris[-ir_sample,] #Select the 30% of rows
View(iris)
#test for single k
pred <- knn(train = scale(ir_train[,-5]),
test = scale(ir_test[,-5]),
cl = ir_train$Species,
k = 40)
accuracy(ir_test$Species, pred)
#LOOP FOR MULTIPLE K's
k_to_try = 1:100
#Find Accuracy of Prediction
accuracy = function(actual, predicted) {
mean(actual == predicted)
}
#test for single k
pred <- knn(train = scale(ir_train[,-5]),
test = scale(ir_test[,-5]),
cl = ir_train$Species,
k = 40)
accuracy(ir_test$Species, pred)
#LOOP FOR MULTIPLE K's
k_to_try = 1:100
acc_k = rep(x = 0, times = length(k_to_try))
for(i in seq_along(k_to_try)) {
pred <- knn(train = scale(ir_train[,-5]),
test = scale(ir_test[,-5]),
cl = ir_train$Species,
k = k_to_try[i])
acc_k[i] <- accuracy(ir_test$Species, pred)
}
plot(acc_k, type = "b", col = "dodgerblue", cex = 1, pch = 20,
xlab = "k, number of neighbors", ylab = "classification accuracy",
main = "Accuracy vs Neighbors")
# add lines indicating k with best accuracy
abline(v = which(acc_k == max(acc_k)), col = "darkorange", lwd = 1.5)
# add line for max accuracy seen
abline(h = max(acc_k), col = "grey", lty = 2)
# First, install the keras R package from GitHub as follows:
devtools::install_github("rstudio/keras")
# The Keras R interface uses the TensorFlow backend engine by default.
# To install both the core Keras library as well as the TensorFlow backend use the install_keras() function:
library(keras)
# The Keras R interface uses the TensorFlow backend engine by default.
# To install both the core Keras library as well as the TensorFlow backend use the install_keras() function:
library(keras)
install_keras()
# First, install the keras R package from GitHub as follows:
devtools::install_github("rstudio/keras")
install.packages('recommenderlab')
library(recommenderlab)
library(data.table)
library(reshape2)
library(ggplot2)
# Read in the movies and ratings data sets
movies <- read.csv("data/movies.csv", stringsAsFactors = FALSE)
ratings <- read.csv("data/ratings.csv", stringsAsFactors = FALSE)
setwd("~/UW class docs/Senior Year/Info 201/mini-demos/recommender")
# Read in the movies and ratings data sets
movies <- read.csv("data/movies.csv", stringsAsFactors = FALSE)
ratings <- read.csv("data/ratings.csv", stringsAsFactors = FALSE)
# Extract genre from movies data frame
genres <- as.data.frame(movies$genres, stringsAsFactors = FALSE)
genres <- as.data.frame(tstrsplit(genres[,1], '[|]', type.convert = TRUE), stringsAsFactors = FALSE)
colnames(genres) <- c(1:10)
genre_list <- c("Action", "Adventure", "Animation", "Children",
"Comedy", "Crime","Documentary", "Drama", "Fantasy",
"Film-Noir", "Horror", "Musical", "Mystery","Romance",
"Sci-Fi", "Thriller", "War", "Western")
# Creates a matrix for the number of movies + 1 and the number of genres
genre_matrix <- matrix(0, 9126, 18)
# Set first row to genre list
genre_matrix[1,] <- genre_list
# Set column names to genre list
colnames(genre_matrix) <- genre_list
# Iterate through matrix
for (i in 1:nrow(genres)) {
for (c in 1:ncol(genres)) {
genmat_col = which(genre_matrix[1,] == genres[i,c])
genre_matrix[i + 1,genmat_col] <- 1
}
}
# Convert the matrix into a data frame
# Remove first row, which was the genre list
genre_matrix <- as.data.frame(genre_matrix[-1,], stringsAsFactors = FALSE)
# Convert from characters to integers
for (c in 1:ncol(genre_matrix)) {
genre_matrix[,c] <- as.integer(genre_matrix[,c])
}
# Selecting relevant data
# Selecting relevant data
# Select minimum number of users per rated movie
# Normalize the data
# Normalize the data
# Remove bias instances of data
# A matrix of recommendations for each user
# A matrix of recommendations for each user
# A matrix of recommendations for each user
# A matrix of recommendations for each user
# A matrix of recommendations for each user
# A matrix of recommendations for each user
# A matrix of recommendations for each user
# A matrix of recommendations for each user
# A matrix of recommendations for each user
# A matrix of recommendations for each user
# A matrix of recommendations for each user
# A matrix of recommendations for each user
# A matrix of recommendations for each user
# A matrix of recommendations for each user
# A matrix of recommendations for each user
# A matrix of recommendations for each user
# A matrix of recommendations for each user
# A matrix of recommendations for each user
# A matrix of recommendations for each user
# A matrix of recommendations for each user
# A matrix of recommendations for each user
# A matrix of recommendations for each user
# A matrix of recommendations for each user
# A matrix of recommendations for each user
# A matrix of recommendations for each user
# A matrix of recommendations for each user
# A matrix of recommendations for each user
# A matrix of recommendations for each user
View(genre_matrix)
